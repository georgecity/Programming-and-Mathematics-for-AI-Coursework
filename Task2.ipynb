{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Task 2: MNIST Digits Classification"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib as plt\n",
    "from tensorflow import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.utils import to_categorical\n",
    "import time\n",
    "from sklearn.metrics import classification_report, confusion_matrix \n",
    "import tensorflow as tf\n",
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from keras.optimizers import SGD\n",
    "from torch.utils.data import random_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "source": [
    "# Loading Dataset and Data Preprocessing"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 432x288 with 1 Axes>",
      "image/svg+xml": "<?xml version=\"1.0\" encoding=\"utf-8\" standalone=\"no\"?>\r\n<!DOCTYPE svg PUBLIC \"-//W3C//DTD SVG 1.1//EN\"\r\n  \"http://www.w3.org/Graphics/SVG/1.1/DTD/svg11.dtd\">\r\n<!-- Created with matplotlib (https://matplotlib.org/) -->\r\n<svg height=\"248.518125pt\" version=\"1.1\" viewBox=\"0 0 251.565 248.518125\" width=\"251.565pt\" xmlns=\"http://www.w3.org/2000/svg\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">\r\n <metadata>\r\n  <rdf:RDF xmlns:cc=\"http://creativecommons.org/ns#\" xmlns:dc=\"http://purl.org/dc/elements/1.1/\" xmlns:rdf=\"http://www.w3.org/1999/02/22-rdf-syntax-ns#\">\r\n   <cc:Work>\r\n    <dc:type rdf:resource=\"http://purl.org/dc/dcmitype/StillImage\"/>\r\n    <dc:date>2020-12-20T08:51:32.530386</dc:date>\r\n    <dc:format>image/svg+xml</dc:format>\r\n    <dc:creator>\r\n     <cc:Agent>\r\n      <dc:title>Matplotlib v3.3.2, https://matplotlib.org/</dc:title>\r\n     </cc:Agent>\r\n    </dc:creator>\r\n   </cc:Work>\r\n  </rdf:RDF>\r\n </metadata>\r\n <defs>\r\n  <style type=\"text/css\">*{stroke-linecap:butt;stroke-linejoin:round;}</style>\r\n </defs>\r\n <g id=\"figure_1\">\r\n  <g id=\"patch_1\">\r\n   <path d=\"M 0 248.518125 \r\nL 251.565 248.518125 \r\nL 251.565 0 \r\nL 0 0 \r\nz\r\n\" style=\"fill:none;\"/>\r\n  </g>\r\n  <g id=\"axes_1\">\r\n   <g id=\"patch_2\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\nL 244.365 7.2 \r\nL 26.925 7.2 \r\nz\r\n\" style=\"fill:#ffffff;\"/>\r\n   </g>\r\n   <g clip-path=\"url(#pa52b2a189b)\">\r\n    <image height=\"218\" id=\"image6feefc88be\" transform=\"scale(1 -1)translate(0 -218)\" width=\"218\" x=\"26.925\" xlink:href=\"data:image/png;base64,\r\niVBORw0KGgoAAAANSUhEUgAAANoAAADaCAYAAADAHVzbAAAGLElEQVR4nO3dTYhN/wPH8TOSiKY8K8nKLJAVJSlPmWLMJA/FrKzYzs4WK6XslSw0JiIrGYWpWUizkWaBLCxMZmGhpqixmOa/+i/0635vznU/45rXa/vpPNSvt1NzOvfXNT8/P18BbbVkoW8AFgOhQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBCxd6BvoVL29vcX9xYsXDbcNGzYUjx0ZGSnuhw8fLu78fTzRIEBoECA0CBAaBAgNAoQGAUKDAO/Ravr69Wvbji29g6uqqjp06FBx7+rq+u17or080SBAaBAgNAgQGgQIDQKEBgFCgwDv0Wo6c+ZMcZ+cnKx97uvXrxf3Zu/Rjh49WvvatIcnGgQIDQKEBgFCgwChQYDQIEBoENA1Pz8/v9A30Ym+f/9e3Pv7+xtu4+PjLV374MGDxX1sbKyl8/PneaJBgNAgQGgQIDQIEBoECA0C/Hm/TW7fvt1wu3jxYluv/fz58+J+5MiRtl6f//JEgwChQYDQIEBoECA0CBAaBAgNAhbtz819/PixuP/48aOl88/NzTXcli9fXjx2dna2pWtfvXq1uK9Zs6b2uXt6eor7ypUra5/7X+aJBgFCgwChQYDQIEBoECA0CBAaBHT092ijo6MNt2vXrhWPffv2bXH/+fNnnVv6KzT7T9rV1VX73Js3by7uy5YtK+69vb0Nt61btxaPPXDgQHHfs2dPcV+6dOFeG3uiQYDQIEBoECA0CBAaBAgNAoQGAR39PdqrV68abhMTE8E7WTy+fPnS0vG3bt36Q3fyX8PDw8V9cHCwbdduxhMNAoQGAUKDAKFBgNAgQGgQ0NF/3t+7d++CXXvfvn3F/ebNmw23bdu2FY998+ZNce/r6yvurXzi0+xTlR07dhT30iuXqqqqmZmZ376n/1u3bl1xP3bsWO1zt5snGgQIDQKEBgFCgwChQYDQIEBoENDRPzdXuvXLly8Xj71x40ZL116ypPxv1P379xtuZ8+ebena58+fr33tZtavX1/c379/X9xXrVpV3L99+9Zwe/nyZfHYgYGB4t7d3V3cF5InGgQIDQKEBgFCgwChQYDQIEBoENDR79FKZmdni/vu3buL+7t37/7k7fzi0aNHxf3UqVPFvdlPvjX7Vm5qaqq4l4yMjBT3c+fO1T73v8wTDQKEBgFCgwChQYDQIEBoECA0CPhn36M18+nTp+J+6dKl4t7s26mSZr9PODY2Vtx37txZ3Jt9r/bgwYPiXtLse7Vm7x/Xrl1b+9qdzBMNAoQGAUKDAKFBgNAgQGgQIDQIWLTv0ZqZnJws7sePHy/u09PTta89PDxc3AcHB4t7s+/Nenp6Gm6t/L/VqqqqHj58WNxPnz7d0vk7lScaBAgNAoQGAUKDAKFBgNAgwJ/3a/r8+XNxHxoaqn3ue/fuFfcVK1bUPndVVdWJEycabk+fPm3p3Nu3by/u4+PjDbd/+RMaTzQIEBoECA0ChAYBQoMAoUGA0CDAe7RF6MmTJw23gYGBtl778ePHDbeTJ0+29doLyRMNAoQGAUKDAKFBgNAgQGgQIDQI8B5tEZqbm2u47d+/v3jsxMRES9cu/dTd69evi8euXr26pWsvJE80CBAaBAgNAoQGAUKDAKFBgNAgwHs0fjE6Olrc+/r62nbtO3fuFPcLFy607drt5okGAUKDAKFBgNAgQGgQIDQIEBoEeI/GL0rfqlVVVfX39xf3Z8+e1b72pk2bivuHDx+Ke3d3d+1rt5snGgQIDQKEBgFCgwChQYDQIMCf9/ktU1NTxX3Xrl3FfWZmpva1p6eni3uz1wMLyRMNAoQGAUKDAKFBgNAgQGgQIDQIWLrQN0Bn2bJlS3EfGhoq7leuXGm43b17t3jsxo0bi/vfzBMNAoQGAUKDAKFBgNAgQGgQIDQI8D0aBHiiQYDQIEBoECA0CBAaBAgNAoQGAUKDAKFBgNAgQGgQIDQIEBoECA0ChAYBQoMAoUGA0CBAaBAgNAgQGgQIDQKEBgFCgwChQYDQIEBoECA0CBAaBAgNAv4He98bdY98CA4AAAAASUVORK5CYII=\" y=\"-6.64\"/>\r\n   </g>\r\n   <g id=\"matplotlib.axis_1\">\r\n    <g id=\"xtick_1\">\r\n     <g id=\"line2d_1\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL 0 3.5 \r\n\" id=\"md745548e4f\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"30.807857\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_1\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(27.626607 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 31.78125 66.40625 \r\nQ 24.171875 66.40625 20.328125 58.90625 \r\nQ 16.5 51.421875 16.5 36.375 \r\nQ 16.5 21.390625 20.328125 13.890625 \r\nQ 24.171875 6.390625 31.78125 6.390625 \r\nQ 39.453125 6.390625 43.28125 13.890625 \r\nQ 47.125 21.390625 47.125 36.375 \r\nQ 47.125 51.421875 43.28125 58.90625 \r\nQ 39.453125 66.40625 31.78125 66.40625 \r\nz\r\nM 31.78125 74.21875 \r\nQ 44.046875 74.21875 50.515625 64.515625 \r\nQ 56.984375 54.828125 56.984375 36.375 \r\nQ 56.984375 17.96875 50.515625 8.265625 \r\nQ 44.046875 -1.421875 31.78125 -1.421875 \r\nQ 19.53125 -1.421875 13.0625 8.265625 \r\nQ 6.59375 17.96875 6.59375 36.375 \r\nQ 6.59375 54.828125 13.0625 64.515625 \r\nQ 19.53125 74.21875 31.78125 74.21875 \r\nz\r\n\" id=\"DejaVuSans-48\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_2\">\r\n     <g id=\"line2d_2\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"69.636429\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_2\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(66.455179 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 10.796875 72.90625 \r\nL 49.515625 72.90625 \r\nL 49.515625 64.59375 \r\nL 19.828125 64.59375 \r\nL 19.828125 46.734375 \r\nQ 21.96875 47.46875 24.109375 47.828125 \r\nQ 26.265625 48.1875 28.421875 48.1875 \r\nQ 40.625 48.1875 47.75 41.5 \r\nQ 54.890625 34.8125 54.890625 23.390625 \r\nQ 54.890625 11.625 47.5625 5.09375 \r\nQ 40.234375 -1.421875 26.90625 -1.421875 \r\nQ 22.3125 -1.421875 17.546875 -0.640625 \r\nQ 12.796875 0.140625 7.71875 1.703125 \r\nL 7.71875 11.625 \r\nQ 12.109375 9.234375 16.796875 8.0625 \r\nQ 21.484375 6.890625 26.703125 6.890625 \r\nQ 35.15625 6.890625 40.078125 11.328125 \r\nQ 45.015625 15.765625 45.015625 23.390625 \r\nQ 45.015625 31 40.078125 35.4375 \r\nQ 35.15625 39.890625 26.703125 39.890625 \r\nQ 22.75 39.890625 18.8125 39.015625 \r\nQ 14.890625 38.140625 10.796875 36.28125 \r\nz\r\n\" id=\"DejaVuSans-53\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_3\">\r\n     <g id=\"line2d_3\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"108.465\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_3\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(102.1025 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 12.40625 8.296875 \r\nL 28.515625 8.296875 \r\nL 28.515625 63.921875 \r\nL 10.984375 60.40625 \r\nL 10.984375 69.390625 \r\nL 28.421875 72.90625 \r\nL 38.28125 72.90625 \r\nL 38.28125 8.296875 \r\nL 54.390625 8.296875 \r\nL 54.390625 0 \r\nL 12.40625 0 \r\nz\r\n\" id=\"DejaVuSans-49\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_4\">\r\n     <g id=\"line2d_4\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"147.293571\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_4\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(140.931071 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_5\">\r\n     <g id=\"line2d_5\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"186.122143\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_5\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(179.759643 239.238437)scale(0.1 -0.1)\">\r\n       <defs>\r\n        <path d=\"M 19.1875 8.296875 \r\nL 53.609375 8.296875 \r\nL 53.609375 0 \r\nL 7.328125 0 \r\nL 7.328125 8.296875 \r\nQ 12.9375 14.109375 22.625 23.890625 \r\nQ 32.328125 33.6875 34.8125 36.53125 \r\nQ 39.546875 41.84375 41.421875 45.53125 \r\nQ 43.3125 49.21875 43.3125 52.78125 \r\nQ 43.3125 58.59375 39.234375 62.25 \r\nQ 35.15625 65.921875 28.609375 65.921875 \r\nQ 23.96875 65.921875 18.8125 64.3125 \r\nQ 13.671875 62.703125 7.8125 59.421875 \r\nL 7.8125 69.390625 \r\nQ 13.765625 71.78125 18.9375 73 \r\nQ 24.125 74.21875 28.421875 74.21875 \r\nQ 39.75 74.21875 46.484375 68.546875 \r\nQ 53.21875 62.890625 53.21875 53.421875 \r\nQ 53.21875 48.921875 51.53125 44.890625 \r\nQ 49.859375 40.875 45.40625 35.40625 \r\nQ 44.1875 33.984375 37.640625 27.21875 \r\nQ 31.109375 20.453125 19.1875 8.296875 \r\nz\r\n\" id=\"DejaVuSans-50\"/>\r\n       </defs>\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"xtick_6\">\r\n     <g id=\"line2d_6\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"224.950714\" xlink:href=\"#md745548e4f\" y=\"224.64\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_6\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(218.588214 239.238437)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"matplotlib.axis_2\">\r\n    <g id=\"ytick_1\">\r\n     <g id=\"line2d_7\">\r\n      <defs>\r\n       <path d=\"M 0 0 \r\nL -3.5 0 \r\n\" id=\"m04bc123d82\" style=\"stroke:#000000;stroke-width:0.8;\"/>\r\n      </defs>\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"11.082857\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_7\">\r\n      <!-- 0 -->\r\n      <g transform=\"translate(13.5625 14.882076)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_2\">\r\n     <g id=\"line2d_8\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"49.911429\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_8\">\r\n      <!-- 5 -->\r\n      <g transform=\"translate(13.5625 53.710647)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_3\">\r\n     <g id=\"line2d_9\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"88.74\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_9\">\r\n      <!-- 10 -->\r\n      <g transform=\"translate(7.2 92.539219)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_4\">\r\n     <g id=\"line2d_10\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"127.568571\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_10\">\r\n      <!-- 15 -->\r\n      <g transform=\"translate(7.2 131.36779)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-49\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_5\">\r\n     <g id=\"line2d_11\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"166.397143\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_11\">\r\n      <!-- 20 -->\r\n      <g transform=\"translate(7.2 170.196362)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-48\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n    <g id=\"ytick_6\">\r\n     <g id=\"line2d_12\">\r\n      <g>\r\n       <use style=\"stroke:#000000;stroke-width:0.8;\" x=\"26.925\" xlink:href=\"#m04bc123d82\" y=\"205.225714\"/>\r\n      </g>\r\n     </g>\r\n     <g id=\"text_12\">\r\n      <!-- 25 -->\r\n      <g transform=\"translate(7.2 209.024933)scale(0.1 -0.1)\">\r\n       <use xlink:href=\"#DejaVuSans-50\"/>\r\n       <use x=\"63.623047\" xlink:href=\"#DejaVuSans-53\"/>\r\n      </g>\r\n     </g>\r\n    </g>\r\n   </g>\r\n   <g id=\"patch_3\">\r\n    <path d=\"M 26.925 224.64 \r\nL 26.925 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_4\">\r\n    <path d=\"M 244.365 224.64 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_5\">\r\n    <path d=\"M 26.925 224.64 \r\nL 244.365 224.64 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n   <g id=\"patch_6\">\r\n    <path d=\"M 26.925 7.2 \r\nL 244.365 7.2 \r\n\" style=\"fill:none;stroke:#000000;stroke-linecap:square;stroke-linejoin:miter;stroke-width:0.8;\"/>\r\n   </g>\r\n  </g>\r\n </g>\r\n <defs>\r\n  <clipPath id=\"pa52b2a189b\">\r\n   <rect height=\"217.44\" width=\"217.44\" x=\"26.925\" y=\"7.2\"/>\r\n  </clipPath>\r\n </defs>\r\n</svg>\r\n",
      "image/png": "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\n"
     },
     "metadata": {
      "needs_background": "light"
     }
    }
   ],
   "source": [
    "train_digits = torchvision.datasets.MNIST(root='./', train=True, download= True, transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]))\n",
    "test_digits = torchvision.datasets.MNIST(root='./', train=False, download= True, transform= transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5,), (0.5,))]))\n",
    "train, val = random_split(train_digits, [55000, 5000])\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(train, batch_size=55000, shuffle=True)\n",
    "val_loader = torch.utils.data.DataLoader(val, batch_size=5000, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(test_digits, batch_size=1000, shuffle=True)\n",
    "\n",
    "trainImages, trainLabels = next(iter(train_loader))\n",
    "testImages, testLabels = next(iter(test_loader))\n",
    "validImages, validLabels = next(iter(val_loader))\n",
    "\n",
    "trainImages = np.array(trainImages)\n",
    "trainLabels = np.array(trainLabels)\n",
    "testImages =np.array(testImages)\n",
    "testLabels =np.array(testLabels)\n",
    "validImages =np.array(validImages)\n",
    "validLabels =np.array(validLabels)\n",
    "\n",
    "plt.imshow( tf.squeeze( testImages[0]) , cmap=plt.cm.binary)\n",
    "\n",
    "testImages = testImages.reshape((-1, 784))\n",
    "trainImages = trainImages.reshape((-1, 784))\n",
    "validImages =validImages.reshape((-1, 784))\n",
    "\n",
    "trainImages = trainImages.astype('float32')\n",
    "testImages = testImages.astype('float32')"
   ]
  },
  {
   "source": [
    "# One Hot encoding of Image Labels"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "trainLabels = to_categorical(trainLabels)\n",
    "testLabels =  to_categorical(testLabels)\n",
    "validLabels = to_categorical(validLabels)"
   ],
   "cell_type": "code",
   "metadata": {},
   "execution_count": 3,
   "outputs": []
  },
  {
   "source": [
    "# Neural Network model with Numpy"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ANN():\n",
    "    def __init__(self, epochs, lr, inp_sizes):\n",
    "        self.epochs = epochs\n",
    "        self.lr = lr\n",
    "        self.inp_sizes = inp_sizes\n",
    "        self.params = self.init_layers()\n",
    "\n",
    "    def relu(self, x ,derivative=False):\n",
    "        if derivative:\n",
    "            x[x<=0] = 0\n",
    "            x[x>0] = 1     \n",
    "            return x\n",
    "        return np.maximum(0,x)\n",
    "\n",
    "    def sigmoid(self, x, derivative=False):\n",
    "        if derivative:\n",
    "            return (np.exp(-x))/((np.exp(-x)+1)**2)\n",
    "        return 1/(1 + np.exp(-x))\n",
    "\n",
    "    def softmax(self, x, derivative=False):\n",
    "        exps = np.exp(x - x.max())\n",
    "        if derivative:\n",
    "            return exps / np.sum(exps, axis=0) * (1 - exps / np.sum(exps, axis=0))\n",
    "        return exps / np.sum(exps, axis=0)\n",
    "\n",
    "    def init_layers(self):\n",
    "        il=self.inp_sizes[0]\n",
    "        l2=self.inp_sizes[1]\n",
    "        l3=self.inp_sizes[2]\n",
    "        l4=self.inp_sizes[3]\n",
    "        ol=self.inp_sizes[4]\n",
    "\n",
    "        params = {\n",
    "            'W1':np.random.randn(l2, il) * np.sqrt(1. / l2),\n",
    "            'W2':np.random.randn(l3, l2) * np.sqrt(1. / l3),\n",
    "            'W3':np.random.randn(l4, l3) * np.sqrt(1. / l4),\n",
    "            'W4':np.random.randn(ol, l4) * np.sqrt(1. / ol)\n",
    "        }\n",
    "\n",
    "        return params\n",
    "\n",
    "    def full_forward(self, trainImages):\n",
    "        params = self.params\n",
    "\n",
    "        params['b0'] = trainImages\n",
    "\n",
    "        params['Z1'] = np.dot(params[\"W1\"], params['b0'])\n",
    "        params['b1'] = self.sigmoid(params['Z1'])\n",
    "\n",
    "        params['Z2'] = np.dot(params[\"W2\"], params['b1'])\n",
    "        params['b2'] = self.relu(params['Z2'])\n",
    "\n",
    "        params['Z3'] = np.dot(params[\"W3\"], params['b2'])\n",
    "        params['b3'] = self.sigmoid(params['Z3'])\n",
    "\n",
    "        params['Z4'] = np.dot(params[\"W4\"], params['b3'])\n",
    "        params['b4'] = self.softmax(params['Z4'])\n",
    "\n",
    "        return params['b4']\n",
    "\n",
    "    def full_backward(self, trainLabels, output):\n",
    "        params = self.params\n",
    "        temp_w = {}\n",
    "\n",
    "        error = 2 * (output - trainLabels) / output.shape[0] * self.softmax(params['Z4'], derivative=True)\n",
    "        temp_w['W4'] = np.outer(error, params['b3'])\n",
    "\n",
    "        error = np.dot(params['W4'].T, error) * self.sigmoid(params['Z3'], derivative=True)\n",
    "        temp_w['W3'] = np.outer(error, params['b2'])\n",
    "\n",
    "        error = np.dot(params['W3'].T, error) * self.relu(params['Z2'], derivative=True)\n",
    "        temp_w['W2'] = np.outer(error, params['b1'])\n",
    "\n",
    "        error = np.dot(params['W2'].T, error) * self.sigmoid(params['Z1'], derivative=True)\n",
    "        temp_w['W1'] = np.outer(error, params['b0'])\n",
    "\n",
    "        return temp_w\n",
    "\n",
    "    def sgd_update(self, update_w):\n",
    "        for key, value in update_w.items():\n",
    "            self.params[key] -= self.lr * value\n",
    "\n",
    "    def acc_metrics(self, testImages, testLabels):\n",
    "        predictions = []\n",
    "\n",
    "        for x, y in zip(testImages, testLabels):\n",
    "            output = self.full_forward(x)\n",
    "            pred = np.argmax(output)\n",
    "            predictions.append(pred == np.argmax(y))\n",
    "        \n",
    "        return np.mean(predictions)\n",
    "\n",
    "    def fit(self, trainImages, trainLabels, testImages, testLabels):\n",
    "        start_time = time.time()\n",
    "        for iteration in range(self.epochs):\n",
    "            for x,y in zip(trainImages, trainLabels):\n",
    "                output = self.full_forward(x)\n",
    "                update_w = self.full_backward(y, output)\n",
    "                self.sgd_update(update_w)\n",
    "            \n",
    "            accuracy = self.acc_metrics(testImages, testLabels)\n",
    "            print('Epoch: {0}, Time Spent: {1:.2f}s, Accuracy: {2:.2f}%'.format(\n",
    "                iteration+1, time.time() - start_time, accuracy * 100\n",
    "            ))\n",
    "    def predict(self, testImages):\n",
    "        predictions = []\n",
    "\n",
    "        for x in testImages:\n",
    "            prediction = self.full_forward(x)\n",
    "            predictions.append(prediction)\n",
    "        \n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch: 1, Time Spent: 24.00s, Accuracy: 21.40%\n",
      "Epoch: 2, Time Spent: 47.99s, Accuracy: 25.40%\n",
      "Epoch: 3, Time Spent: 71.62s, Accuracy: 33.00%\n",
      "Epoch: 4, Time Spent: 95.32s, Accuracy: 39.80%\n",
      "Epoch: 5, Time Spent: 119.44s, Accuracy: 45.80%\n",
      "Epoch: 6, Time Spent: 143.42s, Accuracy: 50.10%\n",
      "Epoch: 7, Time Spent: 168.28s, Accuracy: 56.20%\n",
      "Epoch: 8, Time Spent: 191.78s, Accuracy: 61.00%\n",
      "Epoch: 9, Time Spent: 216.62s, Accuracy: 65.00%\n",
      "Epoch: 10, Time Spent: 241.26s, Accuracy: 67.80%\n",
      "Epoch: 11, Time Spent: 265.38s, Accuracy: 69.70%\n",
      "Epoch: 12, Time Spent: 289.86s, Accuracy: 72.60%\n",
      "Epoch: 13, Time Spent: 314.25s, Accuracy: 74.80%\n",
      "Epoch: 14, Time Spent: 338.56s, Accuracy: 77.20%\n",
      "Epoch: 15, Time Spent: 362.74s, Accuracy: 78.80%\n",
      "Epoch: 16, Time Spent: 387.10s, Accuracy: 79.80%\n",
      "Epoch: 17, Time Spent: 411.46s, Accuracy: 81.00%\n",
      "Epoch: 18, Time Spent: 435.75s, Accuracy: 82.00%\n",
      "Epoch: 19, Time Spent: 460.34s, Accuracy: 82.80%\n",
      "Epoch: 20, Time Spent: 484.76s, Accuracy: 83.30%\n",
      "Epoch: 21, Time Spent: 508.84s, Accuracy: 83.70%\n",
      "Epoch: 22, Time Spent: 532.73s, Accuracy: 84.10%\n",
      "Epoch: 23, Time Spent: 556.47s, Accuracy: 84.60%\n",
      "Epoch: 24, Time Spent: 580.26s, Accuracy: 84.90%\n",
      "Epoch: 25, Time Spent: 604.05s, Accuracy: 85.20%\n",
      "Epoch: 26, Time Spent: 628.00s, Accuracy: 85.20%\n",
      "Epoch: 27, Time Spent: 651.94s, Accuracy: 85.40%\n",
      "Epoch: 28, Time Spent: 675.85s, Accuracy: 85.50%\n",
      "Epoch: 29, Time Spent: 699.75s, Accuracy: 85.70%\n",
      "Epoch: 30, Time Spent: 723.51s, Accuracy: 85.50%\n",
      "Epoch: 31, Time Spent: 747.45s, Accuracy: 85.70%\n",
      "Epoch: 32, Time Spent: 771.66s, Accuracy: 88.30%\n",
      "Epoch: 33, Time Spent: 795.65s, Accuracy: 89.20%\n",
      "Epoch: 34, Time Spent: 819.21s, Accuracy: 89.80%\n",
      "Epoch: 35, Time Spent: 842.76s, Accuracy: 90.30%\n"
     ]
    }
   ],
   "source": [
    "model = ANN( epochs = 35, inp_sizes=[784, 128, 64, 32, 10], lr=0.001)\n",
    "model.fit(trainImages, trainLabels, testImages, testLabels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Accuracy:  0.903\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy: \", model.acc_metrics(testImages, testLabels))\n"
   ]
  },
  {
   "source": [
    "# Predictions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Prediction:  [4 7 0 3 8 4 1 9 4 3 8 7 0 8 4 1 0 1 2 6]\nActual:  [4 7 0 3 5 4 1 9 4 3 8 7 0 8 4 1 0 1 7 6]\n"
     ]
    }
   ],
   "source": [
    "predictions = model.predict(testImages)\n",
    "predictions = np.argmax(predictions, axis = 1)\n",
    "print(\"Prediction: \", predictions[:20])\n",
    "print(\"Actual: \",np.argmax((testLabels[:20]), axis = 1))\n"
   ]
  },
  {
   "source": [
    "# Classification Report and Confusion Matrix"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "              precision    recall  f1-score   support\n\n           0       0.94      0.98      0.96       104\n           1       0.97      0.97      0.97       133\n           2       0.90      0.90      0.90        92\n           3       0.95      0.92      0.94       102\n           4       0.85      0.90      0.87        99\n           5       0.79      0.76      0.77        70\n           6       0.93      0.94      0.93        81\n           7       0.91      0.91      0.91        99\n           8       0.86      0.88      0.87        99\n           9       0.88      0.83      0.85       121\n\n    accuracy                           0.90      1000\n   macro avg       0.90      0.90      0.90      1000\nweighted avg       0.90      0.90      0.90      1000\n\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(np.argmax(testLabels, axis = 1), predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[102   0   2   0   0   0   0   0   0   0]\n [  0 129   0   0   0   0   0   0   4   0]\n [  1   0  83   1   2   1   0   0   3   1]\n [  1   0   0  94   0   3   0   3   1   0]\n [  0   1   0   0  89   1   1   0   0   7]\n [  1   0   1   2   1  53   4   0   5   3]\n [  1   0   1   0   2   1  76   0   0   0]\n [  0   2   2   0   2   1   0  90   0   2]\n [  1   0   2   1   1   4   0   2  87   1]\n [  1   1   1   1   8   3   1   4   1 100]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(testLabels, axis = 1), predictions))"
   ]
  },
  {
   "source": [
    "# Keras Model \n",
    "keras neural network implementation for comparison of results"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model = keras.Sequential([\n",
    "    keras.layers.Dense(64, activation=\"sigmoid\", input_dim=784),\n",
    "    keras.layers.Dense(64, activation=\"relu\"),\n",
    "    keras.layers.Dense(32, activation=\"sigmoid\"),\n",
    "    keras.layers.Dense(32, activation=\"relu\"),\n",
    "    keras.layers.Dense(10, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.7743 - accuracy: 0.7812 - val_loss: 0.3031 - val_accuracy: 0.9148\n",
      "Epoch 2/20\n",
      "550/550 [==============================] - 1s 981us/step - loss: 0.2511 - accuracy: 0.9271 - val_loss: 0.2118 - val_accuracy: 0.9366\n",
      "Epoch 3/20\n",
      "550/550 [==============================] - 1s 984us/step - loss: 0.1788 - accuracy: 0.9468 - val_loss: 0.1828 - val_accuracy: 0.9478\n",
      "Epoch 4/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1449 - accuracy: 0.9567 - val_loss: 0.1481 - val_accuracy: 0.9538\n",
      "Epoch 5/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.1200 - accuracy: 0.9645 - val_loss: 0.1518 - val_accuracy: 0.9548\n",
      "Epoch 6/20\n",
      "550/550 [==============================] - 1s 986us/step - loss: 0.1078 - accuracy: 0.9670 - val_loss: 0.1423 - val_accuracy: 0.9562\n",
      "Epoch 7/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0986 - accuracy: 0.9704 - val_loss: 0.1291 - val_accuracy: 0.9618\n",
      "Epoch 8/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0884 - accuracy: 0.9733 - val_loss: 0.1362 - val_accuracy: 0.9588\n",
      "Epoch 9/20\n",
      "550/550 [==============================] - 1s 987us/step - loss: 0.0818 - accuracy: 0.9752 - val_loss: 0.1257 - val_accuracy: 0.9612\n",
      "Epoch 10/20\n",
      "550/550 [==============================] - 1s 981us/step - loss: 0.0773 - accuracy: 0.9763 - val_loss: 0.1491 - val_accuracy: 0.9556\n",
      "Epoch 11/20\n",
      "550/550 [==============================] - 1s 982us/step - loss: 0.0710 - accuracy: 0.9786 - val_loss: 0.1324 - val_accuracy: 0.9628\n",
      "Epoch 12/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0676 - accuracy: 0.9799 - val_loss: 0.1309 - val_accuracy: 0.9616\n",
      "Epoch 13/20\n",
      "550/550 [==============================] - 1s 981us/step - loss: 0.0638 - accuracy: 0.9796 - val_loss: 0.1292 - val_accuracy: 0.9652\n",
      "Epoch 14/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0603 - accuracy: 0.9813 - val_loss: 0.1267 - val_accuracy: 0.9636\n",
      "Epoch 15/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0556 - accuracy: 0.9826 - val_loss: 0.1526 - val_accuracy: 0.9602\n",
      "Epoch 16/20\n",
      "550/550 [==============================] - 1s 984us/step - loss: 0.0522 - accuracy: 0.9836 - val_loss: 0.1233 - val_accuracy: 0.9658\n",
      "Epoch 17/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0472 - accuracy: 0.9849 - val_loss: 0.1324 - val_accuracy: 0.9654\n",
      "Epoch 18/20\n",
      "550/550 [==============================] - 1s 994us/step - loss: 0.0479 - accuracy: 0.9845 - val_loss: 0.1135 - val_accuracy: 0.9686\n",
      "Epoch 19/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0461 - accuracy: 0.9854 - val_loss: 0.1101 - val_accuracy: 0.9712\n",
      "Epoch 20/20\n",
      "550/550 [==============================] - 1s 1ms/step - loss: 0.0416 - accuracy: 0.9867 - val_loss: 0.1275 - val_accuracy: 0.9664\n",
      "32/32 [==============================] - 0s 807us/step - loss: 0.1290 - accuracy: 0.9640\n"
     ]
    }
   ],
   "source": [
    "opt = keras.optimizers.SGD(lr=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "keras_model.compile(\n",
    "    optimizer=\"adam\",\n",
    "    loss = \"categorical_crossentropy\",\n",
    "    metrics = [\"accuracy\"]\n",
    ")\n",
    "\n",
    "keras_model.fit(\n",
    "    trainImages,\n",
    "    trainLabels,\n",
    "    epochs = 20,\n",
    "    batch_size = 100,\n",
    "    validation_data=(validImages, validLabels)\n",
    ")\n",
    "\n",
    "test_loss, test_acc = keras_model.evaluate(\n",
    "    testImages,\n",
    "    testLabels\n",
    ")\n",
    "\n",
    "keras_predictions = keras_model.predict(testImages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "loss:  0.12904919683933258 Accuracy:  0.9639999866485596\n[4 7 0 3 5 4 1 9 4 3 8 7 0 8 4 1 0 1 7 2]\n[4 7 0 3 5 4 1 9 4 3 8 7 0 8 4 1 0 1 7 6]\n              precision    recall  f1-score   support\n\n           0       0.97      0.99      0.98       104\n           1       0.98      0.98      0.98       133\n           2       0.95      0.97      0.96        92\n           3       0.96      0.95      0.96       102\n           4       0.95      0.92      0.93        99\n           5       0.92      0.94      0.93        70\n           6       0.96      0.95      0.96        81\n           7       1.00      0.96      0.98        99\n           8       0.96      0.98      0.97        99\n           9       0.98      0.98      0.98       121\n\n    accuracy                           0.96      1000\n   macro avg       0.96      0.96      0.96      1000\nweighted avg       0.96      0.96      0.96      1000\n\n"
     ]
    }
   ],
   "source": [
    "print(\"loss: \", test_loss, \"Accuracy: \", test_acc)\n",
    "print(np.argmax(keras_predictions[:20], axis=1))\n",
    "print(np.argmax((testLabels[:20]), axis = 1))\n",
    "print(classification_report(np.argmax(testLabels, axis = 1), np.argmax(keras_predictions, axis = 1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "[[103   0   0   0   0   1   0   0   0   0]\n [  0 131   0   2   0   0   0   0   0   0]\n [  1   1  89   0   0   0   0   0   1   0]\n [  0   0   1  97   0   3   0   0   1   0]\n [  0   1   0   0  91   2   1   0   1   3]\n [  0   0   0   1   1  66   1   0   1   0]\n [  0   0   2   0   2   0  77   0   0   0]\n [  0   1   1   1   1   0   0  95   0   0]\n [  1   0   0   0   0   0   1   0  97   0]\n [  1   0   1   0   1   0   0   0   0 118]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(np.argmax(testLabels, axis=1), np.argmax(keras_predictions, axis = 1)))"
   ]
  }
 ]
}